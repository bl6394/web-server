<html>
<head>
    <meta http-equiv="Content-Type"
          content="text/html; charset=iso-8859-1">
    <title>English Lexicon Project - News - November 10, 2009</title>
</head>
<body>
<h1>Database News and Update - November 10, 2009</h1>
<p>
    The website has been expanded to include new measures of word frequency referred to as SUBTLEX which are based on an
    in press paper by Brysbaert and New (Behavior Research Methods). The paper can be accessed at the Home page under
    SUBTITLE Frequency Paper. Further details regarding these norms are available at <a
        href="http://expsy.ugent.be/subtlexus">http://expsy.ugent.be/subtlexus</a> We have added a button called
    SUBTITLE Frequency, which allows access to each of the following four values:</p>
<ol>
    <li>SUBTL-WF is the SUBTLEX frequency per million words</li>
    <li>LOG10WF. This value is based on log10(number of times the word appears in the corpus + 1)</li>
    <li>SUBTL-CD is the SUBTLEX contextual diversity (% of films containing the word)</li>
    <li>LOG10CD. This value is based on log10(number of films in which the word appears in the corpus + 1)</li>
</ol>
<p>We have expanded the frequency estimates because these measures appear to be particularly useful in accounting for
    LDT and Naming latencies, as demonstrated in the Brysbaert and New paper. There are approximately 4,000 words out of
    the total of 40,481 words that are in the ELP that do not occur in SUBTLEX. These will return a null value in the
    frequency search.</p>
<p>After further investigating the HAL word frequency counts, it has become clear that these norms are based on
    approximately 400 million observations instead of the approximately 131 million originally reported in Lund &
    Burgess. Indeed this likely contributes to the power of these norms in predicting performance.</p>
<p>Also, we have included a paper at the Home Page entitled Multisyllabic Paper (Yap & Balota, 2008), which makes
    extensive use of the ELP datasets, and provides detailed analyses of predictors of lexical decision and naming
    latencies in the dataset.
    Finally, it is important to note that the Kucera and Francis norms have been repeatedly shown to be a relatively
    poor measure of word frequency, and so we STRONGLY encourage users to use the Hal or the new Subtitle frequency
    norms..</p>
<CENTER>
    <FORM><input type="button" Value="Close Window" ONCLICK="window.close()"></FORM>
</CENTER>
</body>
</html>
